{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Deep Q-Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "582c57958a214868908e49ec20b37cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_519642c34be1436491f602bd1ed3e4f8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_23c99ca4c16840e2adea87fa2f863e9d",
              "IPY_MODEL_b28bb1dbaa6d4cf48dd3cd21555ea1c9"
            ]
          }
        },
        "519642c34be1436491f602bd1ed3e4f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "23c99ca4c16840e2adea87fa2f863e9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4182151a1aee4c98b9a983da6574444b",
            "_dom_classes": [],
            "description": "  1%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 8,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3bbca83a69c422a91bc6e5fc1a7d78f"
          }
        },
        "b28bb1dbaa6d4cf48dd3cd21555ea1c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f41bd3ad8aef40d881675f01405c3401",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8/1000 [1:57:48&lt;254:53:26, 925.01s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_02d842234505494b8a2b8257ffac0dde"
          }
        },
        "4182151a1aee4c98b9a983da6574444b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3bbca83a69c422a91bc6e5fc1a7d78f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f41bd3ad8aef40d881675f01405c3401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "02d842234505494b8a2b8257ffac0dde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BeeGass/Deep-Q-Learning/blob/main/Deep_Q_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfsr21qloAQl",
        "outputId": "1db7a9ce-c354-46d3-e819-388bf0797071"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms as T\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gym\n",
        "from gym.wrappers import FrameStack\n",
        "from pdb import set_trace\n",
        "import random\n",
        "from tqdm.notebook import trange\n",
        "import atari_py\n",
        "from google.colab import output\n",
        "!apt update && apt install xvfb\n",
        "!pip install gym-notebook-wrapper\n",
        "import base64\n",
        "import io\n",
        "import gym\n",
        "from gym.wrappers import Monitor\n",
        "from IPython import display\n",
        "from pyvirtualdisplay import Display\n",
        "import copy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connecting to cloud.r-project.o\u001b[0m\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connecting to cloud.r-project.o\u001b[0m\u001b[33m\r0% [1 InRelease gpgv 15.9 kB] [Waiting for headers] [Waiting for headers] [Conn\u001b[0m\r                                                                               \rHit:3 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "\u001b[33m\r0% [1 InRelease gpgv 15.9 kB] [Waiting for headers] [Connecting to cloud.r-proj\u001b[0m\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "\u001b[33m\r0% [1 InRelease gpgv 15.9 kB] [Connecting to cloud.r-project.org] [Connecting t\u001b[0m\r                                                                               \rGet:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "\u001b[33m\r0% [1 InRelease gpgv 15.9 kB] [5 InRelease 17.1 kB/74.6 kB 23%] [Connecting to \u001b[0m\r                                                                               \rHit:6 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "\u001b[33m\r0% [1 InRelease gpgv 15.9 kB] [5 InRelease 17.1 kB/74.6 kB 23%] [Connecting to \u001b[0m\r                                                                               \rHit:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:10 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Fetched 74.6 kB in 2s (43.8 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "76 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.9).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 76 not upgraded.\n",
            "Requirement already satisfied: gym-notebook-wrapper in /usr/local/lib/python3.7/dist-packages (1.2.4)\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (from gym-notebook-wrapper) (2.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from gym-notebook-wrapper) (5.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gym-notebook-wrapper) (3.2.2)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from gym-notebook-wrapper) (0.17.3)\n",
            "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.7/dist-packages (from pyvirtualdisplay->gym-notebook-wrapper) (0.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (5.0.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (56.0.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (4.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gym-notebook-wrapper) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gym-notebook-wrapper) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gym-notebook-wrapper) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gym-notebook-wrapper) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gym-notebook-wrapper) (0.10.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym->gym-notebook-wrapper) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->gym-notebook-wrapper) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->gym-notebook-wrapper) (1.5.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->gym-notebook-wrapper) (0.7.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->gym-notebook-wrapper) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->gym-notebook-wrapper) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->gym-notebook-wrapper) (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->gym-notebook-wrapper) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "vkPgUja71AbE",
        "outputId": "b170d479-3e0f-4d32-d46e-29c26f312094"
      },
      "source": [
        "%%javascript\n",
        "function ConnectButton(){\n",
        "    console.log(\"Connect pushed\"); \n",
        "    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click() \n",
        "}\n",
        "setInterval(ConnectButton,60000);"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "function ConnectButton(){\n",
              "    console.log(\"Connect pushed\"); \n",
              "    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click() \n",
              "}\n",
              "setInterval(ConnectButton,60000);"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p746VD8tIlyz"
      },
      "source": [
        "class Model(nn.Module):\n",
        "  #takes the # of frames stacked and the possible outputs (move right, left, etc)\n",
        "  def __init__(self, numberStacked, possibleOutputs):\n",
        "    super(Model, self).__init__()\n",
        "    hiddenKernels = 8\n",
        "    #layer_one_hiddenKernels = 54\n",
        "    #layer_two_hiddenKernels = 6\n",
        "\n",
        "    #sizePostConvolution = 525824 \n",
        "    #sizePostConvolution = 262912\n",
        "    sizePostConvolution = 53792\n",
        "    #sizePostConvolution = 134400\n",
        "    #self.conv1 = nn.Conv2d(in_channels = numberStacked, out_channels = layer_one_hiddenKernels, kernel_size = 2, stride = 2, padding = 1)\n",
        "    self.conv1 = nn.Conv2d(numberStacked, hiddenKernels, 2)\n",
        "    self.rl = nn.ReLU()\n",
        "    self.conv2 = nn.Conv2d(hiddenKernels, hiddenKernels, 2)\n",
        "    self.fc1 = nn.Linear(sizePostConvolution, possibleOutputs)\n",
        "\n",
        "  def forward(self, stackedState):\n",
        "    x = self.conv1(stackedState)\n",
        "    x = self.rl(x)\n",
        "    x = self.conv2(x)\n",
        "    # print(x.size())\n",
        "    x = x.view(x.size(0), -1)\n",
        "    #x = x.view(-1, x.size()[1] * x.size()[2] * x.size()[3])\n",
        "    #print(x.size())\n",
        "    x = self.fc1(x)\n",
        "    return x\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPYqt0JBEtgR"
      },
      "source": [
        "class Agent():\n",
        "  def __init__(self, size, numberStacked, possibleOutputs, gamma):\n",
        "    self.replay_buffer_size = size\n",
        "    self.replay_buffer_list = []\n",
        "    self.model = Model(numberStacked, possibleOutputs)\n",
        "    self.optimizer = optim.Adam(self.model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "    self.lossFn = torch.nn.MSELoss()\n",
        "    self.gamma = gamma\n",
        "    self.batch_size = 32\n",
        "    self.loss = 0\n",
        "\n",
        "  def action_value(self, input_state):\n",
        "    with torch.no_grad():\n",
        "        q_val = self.model(input_state)\n",
        "    #print(\"q_val: \", q_val)\n",
        "    action = torch.argmax(q_val)\n",
        "    #print(\"action: \", action)\n",
        "    return action\n",
        "\n",
        "  def sample_replay_buffer(self, batch_size):\n",
        "    mini_batch = random.sample(self.replay_buffer_list, batch_size)\n",
        "    return mini_batch\n",
        "\n",
        "  def SGD(self):\n",
        "    mini_batch = self.sample_replay_buffer(self.batch_size)\n",
        "    for batch in mini_batch:\n",
        "        self.optimizer.zero_grad()\n",
        "        state, action, reward, next_state, done = batch\n",
        "        predicted_q_val = self.model(state)\n",
        "        predicted_reward = predicted_q_val[0][torch.argmax(predicted_q_val)]\n",
        "        yj = torch.FloatTensor([reward])\n",
        "#         print(\"the reward: \", reward)\n",
        "        if done:\n",
        "#             if isinstance(yj, float):\n",
        "#                 print(\"this is yj\", yj)\n",
        "            loss = self.lossFn(predicted_reward, yj.detach())\n",
        "        else:\n",
        "            target_q_val = self.model(next_state)\n",
        "            #print(\"target_q_val: \", target_q_val)\n",
        "            yj += self.gamma * torch.argmax(target_q_val)\n",
        "            loss = self.lossFn(predicted_reward, yj.detach())\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "    return loss\n",
        "  \n",
        "  def addToReplay(self, newInput):\n",
        "    if len(self.replay_buffer_list) >= self.replay_buffer_size:#random eviction\n",
        "        toEvict = random.randint(0, self.replay_buffer_size - 1)\n",
        "        del self.replay_buffer_list[0]\n",
        "    self.replay_buffer_list.append(newInput)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQEFVmrc735_"
      },
      "source": [
        "from google.colab import drive\n",
        "model_save_name = 'weights.pt'\n",
        "path = F\"/content/drive/MyDrive/DQN Stuff/Weights/weights.pt\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EMBVNGvT7Nh"
      },
      "source": [
        "class DQN():\n",
        "    def __init__(self):\n",
        "        self.episodes = 1000\n",
        "        self.time_in_episode = 1000000\n",
        "        self.epsilon = 1.0\n",
        "        self.possibleOutputs = 6\n",
        "        self.gamma = 0.01\n",
        "        self.rbSize = 100000\n",
        "        self.numberStacked = 4\n",
        "        # self.height = 210\n",
        "        # self.width = 160\n",
        "        self.height = 84\n",
        "        self.width = 84\n",
        "        self.p_init = 0.7\n",
        "        self.p_end = 0.1\n",
        "        #self.height = 84\n",
        "        #self.width = 84\n",
        "        self.agent = Agent(self.rbSize, self.numberStacked, self.possibleOutputs, self.gamma)\n",
        "        PONG = 'PongNoFrameskip-v4'\n",
        "        CARTPOLE = 'CartPole-v1'\n",
        "        self.test_env = gym.make(PONG)\n",
        "        self.test_env = Monitor(gym.make(PONG),'./', force=True)\n",
        "        self.test_env = FrameStack(self.test_env, self.numberStacked) #stack 4 most recent frames\n",
        "    \n",
        "    def initTransition(self):\n",
        "        state = self.test_env.reset()   \n",
        "        action = self.test_env.action_space.sample()\n",
        "        next_state, reward, done, _ = self.test_env.step(action)\n",
        "        grey_scaled_state = self.preprocessing(state)\n",
        "        grey_scaled_next_state = self.preprocessing(next_state)\n",
        "        transition = (grey_scaled_state, action, reward, grey_scaled_next_state)\n",
        "        self.agent.addToReplay((grey_scaled_state, action, reward, grey_scaled_next_state, done))\n",
        "\n",
        "        return transition\n",
        "\n",
        "    def execute_action(self, input_action, state):\n",
        "        next_state, reward, done, _ = self.test_env.step(input_action)\n",
        "        grey_scaled_next_state = self.preprocessing(next_state)\n",
        "        grey_scaled_state = state\n",
        "        \n",
        "        transition = (grey_scaled_state, input_action, reward, grey_scaled_next_state, done)\n",
        "        self.agent.addToReplay((grey_scaled_state, input_action, reward, grey_scaled_next_state, done))\n",
        "\n",
        "        return transition\n",
        "\n",
        "    def preprocessing(self, input_next_state):\n",
        "        if torch.is_tensor(input_next_state) or not isinstance(input_next_state, gym.wrappers.frame_stack.LazyFrames):\n",
        "            input_next_state = input_next_state.numpy()\n",
        "            next_state = np.transpose(input_next_state, (0, 3, 1, 2))\n",
        "        else:\n",
        "            next_state = np.transpose(input_next_state, (0, 3, 1, 2))#batch h w color to batch color h w\n",
        "\n",
        "#         copy_next_state = np_next_state.copy()\n",
        "\n",
        "        next_state = torch.tensor(next_state, dtype=torch.float)\n",
        "\n",
        "        gTransform = T.Grayscale()\n",
        "        rTransform = T.Resize((84,84))\n",
        "        #transform = T.Compose([ T.Grayscale(), T.ToTensor(), T.ToPILImage()])\n",
        "\n",
        "        next_state = rTransform(next_state)\n",
        "        next_state = gTransform(next_state)\n",
        "        # print(\"next_state\", next_state)\n",
        "        # print(\"next_state\", next_state.size())\n",
        "        # print(\"next_state\", type(next_state))\n",
        "        next_state = next_state.view(1, self.numberStacked, self.height, self.width)\n",
        "\n",
        "        return next_state\n",
        "\n",
        "\n",
        "    def save_weights(self, replay_buffer, epsilon, weights, loss):\n",
        "        the_safe = torch.save({\n",
        "            'epsilon': epsilon,\n",
        "            'model_state_dict': weights,\n",
        "            'replay_buffer': replay_buffer,\n",
        "            'loss': loss,\n",
        "            }, path)\n",
        "  \n",
        "    def train(self):\n",
        "        #next_step = Display()\n",
        "        #next_step.start()\n",
        "        for e in trange(self.episodes):\n",
        "            rewardVal = 0\n",
        "            \n",
        "            #initialize episode and get first transition\n",
        "            initial_transition = self.initTransition()\n",
        "            state, action, reward, next_state = initial_transition\n",
        "\n",
        "            episodeDone = False\n",
        "            time_step = 0\n",
        "#             loss = -100000000000\n",
        "            while not episodeDone:\n",
        "                random_action_prob = random.uniform(0.0, 1.0)\n",
        "                if random_action_prob < self.epsilon:\n",
        "                    action = self.test_env.action_space.sample()\n",
        "                    #print(\"RANDOM action performed: \", action)\n",
        "                else: \n",
        "                    #perform action for timestep\n",
        "                    action = self.agent.action_value(next_state)\n",
        "                    #print(\"action performed: \", action)\n",
        "                    \n",
        "                state, action, reward, next_state, done  = self.execute_action(action, next_state)\n",
        "                \n",
        "                #send all information into our replay buffer so we can test on it within SGD\n",
        "                self.agent.addToReplay((state, action, reward, next_state, done))\n",
        "                \n",
        "                # if ((len(self.agent.replay_buffer) + 1) % self.agent.batch_size) == 0:\n",
        "                if len(self.agent.replay_buffer_list) >= 10000:\n",
        "                    loss = self.agent.SGD()\n",
        "                    \n",
        "                if time_step >= self.time_in_episode or done:\n",
        "                    episodeDone = True\n",
        "                    self.test_env.reset() \n",
        "                time_step += 1 \n",
        "            #perform epsilon decay\n",
        "            episode = e + 1\n",
        "            epsilon_decay_rate = max((self.episodes - episode) / self.episodes, 0)\n",
        "            self.epsilon = (self.p_init - self.p_end) * epsilon_decay_rate + self.p_end\n",
        "\n",
        "            #if (e + 1) % 500 == 0:\n",
        "                #re_buff = copy.deepcopy(self.agent.replay_buffer_list)\n",
        "                #self.save_weights(re_buff, self.epsilon, self.agent.model.state_dict(), loss)\n",
        "\n",
        "        for f in self.test_env.videos:\n",
        "            video = io.open(f[0], 'r+b').read()\n",
        "            encoded = base64.b64encode(video)\n",
        "\n",
        "            display.display(display.HTML(data=\"\"\"\n",
        "            <video alt=\"test\" controls>\n",
        "            <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "            </video>\n",
        "            \"\"\".format(encoded.decode('ascii'))))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596,
          "referenced_widgets": [
            "582c57958a214868908e49ec20b37cdd",
            "519642c34be1436491f602bd1ed3e4f8",
            "23c99ca4c16840e2adea87fa2f863e9d",
            "b28bb1dbaa6d4cf48dd3cd21555ea1c9",
            "4182151a1aee4c98b9a983da6574444b",
            "b3bbca83a69c422a91bc6e5fc1a7d78f",
            "f41bd3ad8aef40d881675f01405c3401",
            "02d842234505494b8a2b8257ffac0dde"
          ]
        },
        "id": "KkY_6X-TnRyB",
        "outputId": "a2b0c81d-09fe-4179-b85d-ae7fc77d8570"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  d = DQN()\n",
        "  DQN.train(d)\n",
        "  #good music\n",
        "  #output.eval_js('new Audio(\"https://r2---sn-p5qlsnsy.googlevideo.com/videoplayback?expire=1618497789&ei=nfx3YLKsELbFlu8P1-64kAY&ip=2600%3A6c64%3A617f%3Abc5a%3A7907%3Aa000%3A7803%3A3c36&id=o-APG1Ow_7Rqcg0H0bk7JmTNziXwYM7ry1DI6oNTus0dER&itag=140&source=youtube&requiressl=yes&mh=zs&mm=31%2C26&mn=sn-p5qlsnsy%2Csn-vgqsknek&ms=au%2Conr&mv=m&mvi=2&pl=32&initcwndbps=2115000&vprv=1&mime=audio%2Fmp4&ns=M8BvnU-4jKyiTm1H_RN4k2gF&gir=yes&clen=58313743&dur=3603.156&lmt=1608958308129032&mt=1618475814&fvip=2&keepalive=yes&fexp=24001373%2C24007246&c=WEB&txp=5431432&n=smqEWuAyGOahL3a&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cvprv%2Cmime%2Cns%2Cgir%2Cclen%2Cdur%2Clmt&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Cinitcwndbps&lsig=AG3C_xAwRQIhAJmKS1ok3DYa04xuKWXRFw6MtJR1ljH66_SW8kE3aq36AiANxg9hEPXANBSNnPBdJIrm8oGF32qcLZxmAqJvtYJJaQ%3D%3D&sig=AOq0QJ8wRQIgSUW-LfEl4Uq8SDC_te4-sqaPRL90RFvIw-xMWmkUADYCIQD8BSmGoAxff-PQruNK4vf5vVXv1Uc5dWK1PHh8EOM40g==\").play()')\n",
        "  #bad music\n",
        "  output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "582c57958a214868908e49ec20b37cdd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-846b17a932d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mDQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;31m#good music\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m#output.eval_js('new Audio(\"https://r2---sn-p5qlsnsy.googlevideo.com/videoplayback?expire=1618497789&ei=nfx3YLKsELbFlu8P1-64kAY&ip=2600%3A6c64%3A617f%3Abc5a%3A7907%3Aa000%3A7803%3A3c36&id=o-APG1Ow_7Rqcg0H0bk7JmTNziXwYM7ry1DI6oNTus0dER&itag=140&source=youtube&requiressl=yes&mh=zs&mm=31%2C26&mn=sn-p5qlsnsy%2Csn-vgqsknek&ms=au%2Conr&mv=m&mvi=2&pl=32&initcwndbps=2115000&vprv=1&mime=audio%2Fmp4&ns=M8BvnU-4jKyiTm1H_RN4k2gF&gir=yes&clen=58313743&dur=3603.156&lmt=1608958308129032&mt=1618475814&fvip=2&keepalive=yes&fexp=24001373%2C24007246&c=WEB&txp=5431432&n=smqEWuAyGOahL3a&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cvprv%2Cmime%2Cns%2Cgir%2Cclen%2Cdur%2Clmt&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Cinitcwndbps&lsig=AG3C_xAwRQIhAJmKS1ok3DYa04xuKWXRFw6MtJR1ljH66_SW8kE3aq36AiANxg9hEPXANBSNnPBdJIrm8oGF32qcLZxmAqJvtYJJaQ%3D%3D&sig=AOq0QJ8wRQIgSUW-LfEl4Uq8SDC_te4-sqaPRL90RFvIw-xMWmkUADYCIQD8BSmGoAxff-PQruNK4vf5vVXv1Uc5dWK1PHh8EOM40g==\").play()')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-db7d450de7f6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;31m# if ((len(self.agent.replay_buffer) + 1) % self.agent.batch_size) == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay_buffer_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_step\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_in_episode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-f8c5db97df83>\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0myj\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_q_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlossFn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}