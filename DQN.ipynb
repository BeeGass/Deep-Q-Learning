{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOy+3a6YFp3m5Q1XgHQpIEd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BeeGassy/Deep-Q-Learning/blob/main/DQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfsr21qloAQl"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms as T\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gym\n",
        "from gym.wrappers import FrameStack\n",
        "from pdb import set_trace\n",
        "import random\n",
        "from tqdm import trange\n",
        "import atari_py"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p746VD8tIlyz"
      },
      "source": [
        "class Model(nn.Module):\n",
        "  #takes the # of frames stacked and the possible outputs (move right, left, etc)\n",
        "  def __init__(self, numberStacked, possibleOutputs):\n",
        "    super(Model, self).__init__()\n",
        "    hiddenKernels = 16\n",
        "\n",
        "    sizePostConvolution = 525824 #figure this out, depends on how we modify the env\n",
        "    self.conv1 = nn.Conv2d(numberStacked, hiddenKernels, 2)\n",
        "    self.rl = nn.ReLU()\n",
        "    self.conv2 = nn.Conv2d(hiddenKernels, hiddenKernels, 2)\n",
        "    self.fc1 = nn.Linear(sizePostConvolution, possibleOutputs)\n",
        "\n",
        "  def forward(self, stackedState):\n",
        "    x = self.conv1(stackedState)\n",
        "    x = self.rl(x)\n",
        "    x = self.conv2(x)\n",
        "    print(x.size())\n",
        "    x = x.view(x.size(0), -1)\n",
        "    #x = x.view(-1, x.size()[1] * x.size()[2] * x.size()[3])\n",
        "    x = self.fc1(x)\n",
        "    return x"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPYqt0JBEtgR"
      },
      "source": [
        "class Agent():\n",
        "  def __init__(self, size, numberStacked, possibleOutputs, gamma):\n",
        "    self.replay_buffer_size = size\n",
        "    self.replay_buffer_list = []\n",
        "    self.m = Model(numberStacked, possibleOutputs)\n",
        "    self.optimizer = optim.Adam(self.m.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "    self.lossFn = torch.nn.MSELoss()\n",
        "    self.gamma = gamma\n",
        "    self.batch_size = 16\n",
        "\n",
        "  def action_value(self, input_state):\n",
        "    with torch.no_grad():\n",
        "        q_val = self.m(input_state)\n",
        "    action = torch.argmax(q_val)\n",
        "    return action\n",
        "\n",
        "  def sample_replay_buffer(self, batch_size):\n",
        "    #print(len(self.replay_buffer_list))\n",
        "    choices = np.random.choice(len(self.replay_buffer_list), batch_size)\n",
        "    perm = torch.tensor(choices)\n",
        "    idx = perm[:batch_size]\n",
        "    samples = np.array(self.replay_buffer_list)[idx]\n",
        "    return samples\n",
        "\n",
        "  def SGD(self):\n",
        "    mini_batch = self.sample_replay_buffer(self.batch_size)\n",
        "    for batch in mini_batch:\n",
        "        self.optimizer.zero_grad()\n",
        "        state, action, reward, next_state, done = batch\n",
        "        yj = reward\n",
        "        print(\"the reward\", yj)\n",
        "        if not done:\n",
        "          print(\"the type for next state:\", type(next_state))\n",
        "          if type(next_state) != type(torch.tensor([])): \n",
        "            set_trace()\n",
        "          target_q_val = self.m(next_state) \n",
        "          #best_predicted_action = torch.argmax(q_val)\n",
        "          #best_predicted_next_state, best_predicted_reward, done, _ = d.test_env.step(best_predicted_action)\n",
        "          print(\"target_q_val: \", target_q_val)\n",
        "          yj += self.gamma * target_q_val\n",
        "        \n",
        "        predicted_q_val = self.m(state)\n",
        "        predicted_reward = torch.max(predicted_q_val)\n",
        "        #predicted_next_state, predicted_reward, done, _ = d.test_env.step(predicted_action)\n",
        "        print(\"type of yj: \", type(yj))\n",
        "        print(\"type of predicted_reward: \", type(predicted_reward))\n",
        "        loss = self.lossFn(predicted_reward, yj.detach())\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "    return loss\n",
        "  \n",
        "  def addToReplay(self, newInput):\n",
        "    print(\"ENTERING addToReplay\")\n",
        "    if len(self.replay_buffer_list) >= self.replay_buffer_size:#random eviction\n",
        "        toEvict = random.randint(0, self.rb_size)\n",
        "        del replay_buffer_list[toEvict]\n",
        "    self.replay_buffer_list.append(newInput)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EMBVNGvT7Nh"
      },
      "source": [
        "class DQN():\n",
        "  def __init__(self):\n",
        "    self.episodes = 400\n",
        "    self.time_in_episode = 1000000\n",
        "    self.epsilon = 0.7\n",
        "    self.possibleOutputs = 6\n",
        "    self.gamma = 0.01\n",
        "    self.rbSize = 100000\n",
        "    self.numberStacked = 4\n",
        "    self.height = 210\n",
        "    self.width = 160\n",
        "    self.agent = Agent(self.rbSize, self.numberStacked, self.possibleOutputs, self.gamma)\n",
        "    DEFAULT_ENV_NAME = 'PongNoFrameskip-v4'\n",
        "    self.test_env = gym.make(DEFAULT_ENV_NAME)\n",
        "    self.test_env = self.stack_frames(self.test_env, self.numberStacked)\n",
        "    \n",
        "  def initTransition(self, isStart):\n",
        "    print(\"ENTERING initTransition\")\n",
        "    state = self.test_env.reset()   \n",
        "    action = self.test_env.action_space.sample()\n",
        "    next_state, reward, done, _ = self.test_env.step(action)\n",
        "    grey_scaled_state = self.preprocessing(state, isStart) \n",
        "    grey_scaled_next_state = self.preprocessing(next_state, isStart)\n",
        "    transition = (grey_scaled_state, action, reward, grey_scaled_next_state)\n",
        "    self.agent.addToReplay((grey_scaled_state, action, reward, grey_scaled_next_state, done))\n",
        "\n",
        "    return transition\n",
        "\n",
        "  def execute_action(self, input_action, state, isStart):\n",
        "    print(\"ENTERING EXECUTE ACTION\")\n",
        "    next_state, reward, done, _ = self.test_env.step(input_action)\n",
        "    print(\"entering grey_scaled_next_state preprocessing\")\n",
        "    grey_scaled_next_state = self.preprocessing(next_state, isStart)\n",
        "\n",
        "    print(\"entering grey_scaled_state preprocessing\")\n",
        "    grey_scaled_state = self.preprocessing(state, isStart)\n",
        "    transition = (grey_scaled_state, input_action, reward, grey_scaled_next_state, done)\n",
        "    self.agent.addToReplay((grey_scaled_state, input_action, reward, grey_scaled_next_state, done))\n",
        "\n",
        "    return transition\n",
        "\n",
        "  def preprocessing(self, input_next_state, isStart):\n",
        "    print(\"entering preprocessing\")\n",
        "    print(\"input_next_state SHAPE: \", input_next_state.shape)\n",
        "    print(\"input_next_state TYPE: \", type(input_next_state))\n",
        "\n",
        "    if torch.is_tensor(input_next_state) or not isinstance(input_next_state, gym.wrappers.frame_stack.LazyFrames):\n",
        "      input_next_state = input_next_state.numpy()\n",
        "\n",
        "    np_next_state = np.transpose(input_next_state, (0, 3, 1, 2))#batch h w color to batch color h w\n",
        "    copy_next_state = np_next_state.copy()\n",
        "\n",
        "    torch_next_state = torch.tensor(copy_next_state, dtype=torch.float)\n",
        "    print(\"torch_next_state SHAPE: \", torch_next_state.shape)\n",
        "    print(\"torch_next_state TYPE: \", type(torch_next_state))\n",
        "\n",
        "    transform = T.Grayscale()\n",
        "    #transform = T.Compose([ T.Grayscale(), T.ToTensor(), T.ToPILImage()])\n",
        "\n",
        "\n",
        "    grey_scaled_next_state = transform(torch_next_state)\n",
        "    grey_scaled_next_state = grey_scaled_next_state.view(1, self.numberStacked, self.height, self.width)\n",
        "    print(\"grey_scaled_next_state SHAPE: \", grey_scaled_next_state.shape)\n",
        "    print(\"grey_scaled_next_state TYPE: \", type(grey_scaled_next_state))\n",
        "    print(\"----------------------\")\n",
        "\n",
        "    return grey_scaled_next_state\n",
        "\n",
        "\n",
        "  #stack the frames of the states in group of 4. 4 Frames per stack\n",
        "  def stack_frames(self, input_env, stack_count):\n",
        "    enviroment = FrameStack(input_env, stack_count)\n",
        "\n",
        "    return enviroment\n",
        "  \n",
        "  def train(self):\n",
        "    for e in trange(self.episodes):\n",
        "      print(\"\\n----------------------------------------------------------------------\\n\")\n",
        "      print(\"\\n----------------------------------------------------------------------\\n\")\n",
        "      rewardVal = 0\n",
        "\n",
        "      #initialize episode and get first transition\n",
        "      isStart = True\n",
        "      initial_transition = self.initTransition(isStart)\n",
        "      state, action, reward, next_state = initial_transition\n",
        "\n",
        "      counter = 0\n",
        "      for time_step in range(self.time_in_episode):\n",
        "        print(counter)\n",
        "        print(\"\\n----------------------------------------------------------------------\\n\")\n",
        "        random_action_prob = random.uniform(0.0, 1.0)\n",
        "        if random_action_prob < self.epsilon:\n",
        "          action = self.test_env.action_space.sample()\n",
        "        else: \n",
        "          #perform action for timestep\n",
        "          action = self.agent.action_value(next_state)\n",
        "\n",
        "        state, action, reward, next_state, done  = self.execute_action(action, next_state, isStart)\n",
        "        isStart = False\n",
        "\n",
        "        #send all information into our replay buffer so we can test on it within SGD\n",
        "        self.agent.addToReplay((state, action, reward, next_state, done))\n",
        "        print(\"ENTERING SGD\")\n",
        "        self.agent.SGD()\n",
        "\n",
        "        #perform epsilon decay\n",
        "        epsilon_decay_rate = max((e - time_step) / e, 0)\n",
        "        epsilon -= epsilon_decay_rate\n",
        "        count += 1 \n",
        "        \n",
        "      #only render every 100 episodes\n",
        "      if e % 100 == 0 and e > 0:\n",
        "        self.test_env.render()    "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkY_6X-TnRyB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b0491119-e93a-4277-9178-f2ecd663857e"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  d = DQN()\n",
        "  DQN.train(d)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/400 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "ENTERING initTransition\n",
            "entering preprocessing\n",
            "input_next_state SHAPE:  (4, 210, 160, 3)\n",
            "input_next_state TYPE:  <class 'gym.wrappers.frame_stack.LazyFrames'>\n",
            "torch_next_state SHAPE:  torch.Size([4, 3, 210, 160])\n",
            "torch_next_state TYPE:  <class 'torch.Tensor'>\n",
            "grey_scaled_next_state SHAPE:  torch.Size([1, 4, 210, 160])\n",
            "grey_scaled_next_state TYPE:  <class 'torch.Tensor'>\n",
            "----------------------\n",
            "entering preprocessing\n",
            "input_next_state SHAPE:  (4, 210, 160, 3)\n",
            "input_next_state TYPE:  <class 'gym.wrappers.frame_stack.LazyFrames'>\n",
            "torch_next_state SHAPE:  torch.Size([4, 3, 210, 160])\n",
            "torch_next_state TYPE:  <class 'torch.Tensor'>\n",
            "grey_scaled_next_state SHAPE:  torch.Size([1, 4, 210, 160])\n",
            "grey_scaled_next_state TYPE:  <class 'torch.Tensor'>\n",
            "----------------------\n",
            "ENTERING addToReplay\n",
            "0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "torch.Size([1, 16, 208, 158])\n",
            "ENTERING EXECUTE ACTION\n",
            "entering grey_scaled_next_state preprocessing\n",
            "entering preprocessing\n",
            "input_next_state SHAPE:  (4, 210, 160, 3)\n",
            "input_next_state TYPE:  <class 'gym.wrappers.frame_stack.LazyFrames'>\n",
            "torch_next_state SHAPE:  torch.Size([4, 3, 210, 160])\n",
            "torch_next_state TYPE:  <class 'torch.Tensor'>\n",
            "grey_scaled_next_state SHAPE:  torch.Size([1, 4, 210, 160])\n",
            "grey_scaled_next_state TYPE:  <class 'torch.Tensor'>\n",
            "----------------------\n",
            "entering grey_scaled_state preprocessing\n",
            "entering preprocessing\n",
            "input_next_state SHAPE:  torch.Size([1, 4, 210, 160])\n",
            "input_next_state TYPE:  <class 'torch.Tensor'>\n",
            "torch_next_state SHAPE:  torch.Size([1, 160, 4, 210])\n",
            "torch_next_state TYPE:  <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a3332faf5af0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mDQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-4faea38c30b7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m           \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misStart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0misStart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-4faea38c30b7>\u001b[0m in \u001b[0;36mexecute_action\u001b[0;34m(self, input_action, state, isStart)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"entering grey_scaled_state preprocessing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mgrey_scaled_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misStart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mtransition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrey_scaled_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrey_scaled_next_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddToReplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrey_scaled_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrey_scaled_next_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-4faea38c30b7>\u001b[0m in \u001b[0;36mpreprocessing\u001b[0;34m(self, input_next_state, isStart)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mgrey_scaled_next_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_next_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mgrey_scaled_next_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrey_scaled_next_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumberStacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grey_scaled_next_state SHAPE: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrey_scaled_next_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m   1464\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mGrayscaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m         \"\"\"\n\u001b[0;32m-> 1466\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgb_to_grayscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_output_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_output_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mrgb_to_grayscale\u001b[0;34m(img, num_output_channels)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_grayscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_output_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgb_to_grayscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_output_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional_tensor.py\u001b[0m in \u001b[0;36mrgb_to_grayscale\u001b[0;34m(img, num_output_channels)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input image tensor should have at least 3 dimensions, but found {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0m_assert_channels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_output_channels\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional_tensor.py\u001b[0m in \u001b[0;36m_assert_channels\u001b[0;34m(img, permitted)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_image_num_channels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpermitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input image tensor permitted channel values are {}, but found {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpermitted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Input image tensor permitted channel values are [3], but found 160"
          ]
        }
      ]
    }
  ]
}