{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1XNtOT0oaAjFFLz5Y-MLgvnNq23hs5Erd",
      "authorship_tag": "ABX9TyPOwNfzfdiVQL2XPebRrxGi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "719c875899014fb29b51c784bb8c7c75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eb00132a7f834cdd86bfcf84684bfdbf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4f112b0ce7884611a65be51a72b900af",
              "IPY_MODEL_dac43460d47f498fbcb0003460ca7cb0"
            ]
          }
        },
        "eb00132a7f834cdd86bfcf84684bfdbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f112b0ce7884611a65be51a72b900af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c932912d52bc4513a75a85d2f587ac1b",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb18e78953284125b736a7c011568713"
          }
        },
        "dac43460d47f498fbcb0003460ca7cb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cdbb77ac06014a1c9f8e66cd96a36a38",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/400 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_daf131e91a5143a28053d5b441f828d7"
          }
        },
        "c932912d52bc4513a75a85d2f587ac1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb18e78953284125b736a7c011568713": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cdbb77ac06014a1c9f8e66cd96a36a38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "daf131e91a5143a28053d5b441f828d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BeeGassy/Deep-Q-Learning/blob/main/DQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfsr21qloAQl"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms as T\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gym\n",
        "from gym.wrappers import FrameStack\n",
        "from pdb import set_trace\n",
        "import random\n",
        "from tqdm.notebook import trange\n",
        "import atari_py\n",
        "from google.colab import output"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkPgUja71AbE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "5b7ce6be-c374-4302-8070-046a79c46bf3"
      },
      "source": [
        "%%javascript\n",
        "function ConnectButton(){\n",
        "    console.log(\"Connect pushed\"); \n",
        "    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click() \n",
        "}\n",
        "setInterval(ConnectButton,60000);"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "function ConnectButton(){\n",
              "    console.log(\"Connect pushed\"); \n",
              "    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click() \n",
              "}\n",
              "setInterval(ConnectButton,60000);"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p746VD8tIlyz"
      },
      "source": [
        "class Model(nn.Module):\n",
        "  #takes the # of frames stacked and the possible outputs (move right, left, etc)\n",
        "  def __init__(self, numberStacked, possibleOutputs):\n",
        "    super(Model, self).__init__()\n",
        "    hiddenKernels = 16\n",
        "\n",
        "    sizePostConvolution = 525824 \n",
        "    #sizePostConvolution = 134400\n",
        "    self.conv1 = nn.Conv2d(numberStacked, hiddenKernels, 2)\n",
        "    self.rl = nn.ReLU()\n",
        "    self.conv2 = nn.Conv2d(hiddenKernels, hiddenKernels, 2)\n",
        "    self.fc1 = nn.Linear(sizePostConvolution, possibleOutputs)\n",
        "\n",
        "  def forward(self, stackedState):\n",
        "    x = self.conv1(stackedState)\n",
        "    x = self.rl(x)\n",
        "    x = self.conv2(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    #x = x.view(-1, x.size()[1] * x.size()[2] * x.size()[3])\n",
        "    x = self.fc1(x)\n",
        "    return x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPYqt0JBEtgR"
      },
      "source": [
        "class Agent():\n",
        "  def __init__(self, size, numberStacked, possibleOutputs, gamma):\n",
        "    self.replay_buffer_size = size\n",
        "    self.replay_buffer_list = []\n",
        "    self.model = Model(numberStacked, possibleOutputs)\n",
        "    self.optimizer = optim.Adam(self.model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "    self.lossFn = torch.nn.MSELoss()\n",
        "    self.gamma = gamma\n",
        "    self.batch_size = 10\n",
        "\n",
        "  def action_value(self, input_state):\n",
        "    with torch.no_grad():\n",
        "        q_val = self.model(input_state)\n",
        "    action = torch.argmax(q_val)\n",
        "    return action\n",
        "\n",
        "  def sample_replay_buffer(self, batch_size):\n",
        "    mini_batch = random.sample(self.replay_buffer_list, batch_size)\n",
        "    return mini_batch\n",
        "\n",
        "  def SGD(self):\n",
        "    mini_batch = self.sample_replay_buffer(self.batch_size)\n",
        "    for batch in mini_batch:\n",
        "        self.optimizer.zero_grad()\n",
        "        state, action, reward, next_state, done = batch\n",
        "        predicted_q_val = self.model(state)\n",
        "        predicted_reward = torch.max(predicted_q_val)\n",
        "        #predicted_next_state, predicted_reward, done, _ = d.test_env.step(predicted_action)\n",
        "        yj = torch.FloatTensor([reward])\n",
        "        if done:\n",
        "          if isinstance(yj, float):\n",
        "            print(\"this is yj\", yj)\n",
        "          loss = self.lossFn(predicted_reward, yj.detach())\n",
        "          loss.backward()\n",
        "          self.optimizer.step()\n",
        "          break\n",
        "\n",
        "        target_q_val = self.model(next_state)\n",
        "        #print(\"target_q_val: \", target_q_val)\n",
        "        yj += self.gamma * torch.max(target_q_val)\n",
        "        loss = self.lossFn(predicted_reward, yj)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "    return loss\n",
        "  \n",
        "  def addToReplay(self, newInput):\n",
        "    if len(self.replay_buffer_list) >= self.replay_buffer_size:#random eviction\n",
        "        toEvict = random.randint(0, self.replay_buffer_size)\n",
        "        del replay_buffer_list[toEvict]\n",
        "    self.replay_buffer_list.append(newInput)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EMBVNGvT7Nh"
      },
      "source": [
        "class DQN():\n",
        "  def __init__(self):\n",
        "    self.episodes = 400\n",
        "    self.time_in_episode = 1000000\n",
        "    self.epsilon = 0.7\n",
        "    self.possibleOutputs = 6\n",
        "    self.gamma = 0.01\n",
        "    self.rbSize = 100000\n",
        "    self.numberStacked = 4\n",
        "    self.height = 210\n",
        "    self.width = 160\n",
        "    self.agent = Agent(self.rbSize, self.numberStacked, self.possibleOutputs, self.gamma)\n",
        "    PONG = 'PongNoFrameskip-v4'\n",
        "    CARTPOLE = 'CartPole-v1'\n",
        "    self.test_env = gym.make(PONG)\n",
        "    self.test_env = self.stack_frames(self.test_env, self.numberStacked)\n",
        "    \n",
        "  def initTransition(self, isStart):\n",
        "    state = self.test_env.reset()   \n",
        "    action = self.test_env.action_space.sample()\n",
        "    next_state, reward, done, _ = self.test_env.step(action)\n",
        "    grey_scaled_state = self.preprocessing(state, isStart)\n",
        "    grey_scaled_next_state = self.preprocessing(next_state, isStart)\n",
        "    transition = (grey_scaled_state, action, reward, grey_scaled_next_state)\n",
        "    self.agent.addToReplay((grey_scaled_state, action, reward, grey_scaled_next_state, done))\n",
        "\n",
        "    return transition\n",
        "\n",
        "  def execute_action(self, input_action, state, isStart):\n",
        "    next_state, reward, done, _ = self.test_env.step(input_action)\n",
        "    grey_scaled_next_state = self.preprocessing(next_state, isStart)\n",
        "    grey_scaled_state = state\n",
        "    \n",
        "    transition = (grey_scaled_state, input_action, reward, grey_scaled_next_state, done)\n",
        "    self.agent.addToReplay((grey_scaled_state, input_action, reward, grey_scaled_next_state, done))\n",
        "\n",
        "    return transition\n",
        "\n",
        "  def preprocessing(self, input_next_state, isStart):\n",
        "    if torch.is_tensor(input_next_state) or not isinstance(input_next_state, gym.wrappers.frame_stack.LazyFrames):\n",
        "      input_next_state = input_next_state.numpy()\n",
        "\n",
        "      np_next_state = np.transpose(input_next_state, (0, 3, 1, 2))\n",
        "    else:\n",
        "      np_next_state = np.transpose(input_next_state, (0, 3, 1, 2))#batch h w color to batch color h w\n",
        "\n",
        "    copy_next_state = np_next_state.copy()\n",
        "\n",
        "    torch_next_state = torch.tensor(copy_next_state, dtype=torch.float)\n",
        "\n",
        "    transform = T.Grayscale()\n",
        "    #transform = T.Compose([ T.Grayscale(), T.ToTensor(), T.ToPILImage()])\n",
        "\n",
        "\n",
        "    grey_scaled_next_state = transform(torch_next_state)\n",
        "    grey_scaled_next_state = grey_scaled_next_state.view(1, self.numberStacked, self.height, self.width)\n",
        "\n",
        "    return grey_scaled_next_state\n",
        "\n",
        "\n",
        "  #stack the frames of the states in group of 4. 4 Frames per stack\n",
        "  def stack_frames(self, input_env, stack_count):\n",
        "    enviroment = FrameStack(input_env, stack_count)\n",
        "\n",
        "    return enviroment\n",
        "  \n",
        "  def train(self):\n",
        "    for e in trange(self.episodes):\n",
        "      rewardVal = 0\n",
        "\n",
        "      #initialize episode and get first transition\n",
        "      isStart = True\n",
        "      initial_transition = self.initTransition(isStart)\n",
        "      state, action, reward, next_state = initial_transition\n",
        "\n",
        "      episodeDone = False\n",
        "      time_step = 0\n",
        "      while not episodeDone:\n",
        "        random_action_prob = random.uniform(0.0, 1.0)\n",
        "        if random_action_prob < self.epsilon:\n",
        "          action = self.test_env.action_space.sample()\n",
        "        else: \n",
        "          #perform action for timestep\n",
        "          action = self.agent.action_value(next_state)\n",
        "\n",
        "        state, action, reward, next_state, done  = self.execute_action(action, next_state, isStart)\n",
        "        isStart = False\n",
        "\n",
        "        #send all information into our replay buffer so we can test on it within SGD\n",
        "        self.agent.addToReplay((state, action, reward, next_state, done))\n",
        "\n",
        "        if ((self.agent.replay_buffer_size + 1) % self.agent.batch_size) == 0:\n",
        "            self.agent.SGD()\n",
        "\n",
        "        #perform epsilon decay\n",
        "        episode = e + 1\n",
        "        epsilon_decay_rate = max((episode - time_step) / episode, 0)\n",
        "        self.epsilon -= epsilon_decay_rate\n",
        "        if time_step >= self.time_in_episode or done:\n",
        "          episodeDone = True\n",
        "        time_step += 1 \n",
        "        \n",
        "      #only render every 100 episodes\n",
        "      if e % 40 == 0 and e > 0:\n",
        "        self.test_env.render()    "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkY_6X-TnRyB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477,
          "referenced_widgets": [
            "719c875899014fb29b51c784bb8c7c75",
            "eb00132a7f834cdd86bfcf84684bfdbf",
            "4f112b0ce7884611a65be51a72b900af",
            "dac43460d47f498fbcb0003460ca7cb0",
            "c932912d52bc4513a75a85d2f587ac1b",
            "eb18e78953284125b736a7c011568713",
            "cdbb77ac06014a1c9f8e66cd96a36a38",
            "daf131e91a5143a28053d5b441f828d7"
          ]
        },
        "outputId": "f38017d5-4743-471a-8fa2-1c6d01f7ff4e"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  d = DQN()\n",
        "  DQN.train(d)\n",
        "  #good music\n",
        "  output.eval_js('new Audio(\"https://r2---sn-p5qlsnsy.googlevideo.com/videoplayback?expire=1618497789&ei=nfx3YLKsELbFlu8P1-64kAY&ip=2600%3A6c64%3A617f%3Abc5a%3A7907%3Aa000%3A7803%3A3c36&id=o-APG1Ow_7Rqcg0H0bk7JmTNziXwYM7ry1DI6oNTus0dER&itag=140&source=youtube&requiressl=yes&mh=zs&mm=31%2C26&mn=sn-p5qlsnsy%2Csn-vgqsknek&ms=au%2Conr&mv=m&mvi=2&pl=32&initcwndbps=2115000&vprv=1&mime=audio%2Fmp4&ns=M8BvnU-4jKyiTm1H_RN4k2gF&gir=yes&clen=58313743&dur=3603.156&lmt=1608958308129032&mt=1618475814&fvip=2&keepalive=yes&fexp=24001373%2C24007246&c=WEB&txp=5431432&n=smqEWuAyGOahL3a&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cvprv%2Cmime%2Cns%2Cgir%2Cclen%2Cdur%2Clmt&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Cinitcwndbps&lsig=AG3C_xAwRQIhAJmKS1ok3DYa04xuKWXRFw6MtJR1ljH66_SW8kE3aq36AiANxg9hEPXANBSNnPBdJIrm8oGF32qcLZxmAqJvtYJJaQ%3D%3D&sig=AOq0QJ8wRQIgSUW-LfEl4Uq8SDC_te4-sqaPRL90RFvIw-xMWmkUADYCIQD8BSmGoAxff-PQruNK4vf5vVXv1Uc5dWK1PHh8EOM40g==\").play()')\n",
        "  #bad music\n",
        "  #output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "719c875899014fb29b51c784bb8c7c75",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ab7f3a8a93ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mDQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;31m#good music\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'new Audio(\"https://r2---sn-p5qlsnsy.googlevideo.com/videoplayback?expire=1618497789&ei=nfx3YLKsELbFlu8P1-64kAY&ip=2600%3A6c64%3A617f%3Abc5a%3A7907%3Aa000%3A7803%3A3c36&id=o-APG1Ow_7Rqcg0H0bk7JmTNziXwYM7ry1DI6oNTus0dER&itag=140&source=youtube&requiressl=yes&mh=zs&mm=31%2C26&mn=sn-p5qlsnsy%2Csn-vgqsknek&ms=au%2Conr&mv=m&mvi=2&pl=32&initcwndbps=2115000&vprv=1&mime=audio%2Fmp4&ns=M8BvnU-4jKyiTm1H_RN4k2gF&gir=yes&clen=58313743&dur=3603.156&lmt=1608958308129032&mt=1618475814&fvip=2&keepalive=yes&fexp=24001373%2C24007246&c=WEB&txp=5431432&n=smqEWuAyGOahL3a&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cvprv%2Cmime%2Cns%2Cgir%2Cclen%2Cdur%2Clmt&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Cinitcwndbps&lsig=AG3C_xAwRQIhAJmKS1ok3DYa04xuKWXRFw6MtJR1ljH66_SW8kE3aq36AiANxg9hEPXANBSNnPBdJIrm8oGF32qcLZxmAqJvtYJJaQ%3D%3D&sig=AOq0QJ8wRQIgSUW-LfEl4Uq8SDC_te4-sqaPRL90RFvIw-xMWmkUADYCIQD8BSmGoAxff-PQruNK4vf5vVXv1Uc5dWK1PHh8EOM40g==\").play()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-e31716ed4e8e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0;31m#initialize episode and get first transition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0misStart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m       \u001b[0minitial_transition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitTransition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misStart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m       \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_transition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-e31716ed4e8e>\u001b[0m in \u001b[0;36minitTransition\u001b[0;34m(self, isStart)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mgrey_scaled_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misStart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mgrey_scaled_next_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misStart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtransition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrey_scaled_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrey_scaled_next_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-e31716ed4e8e>\u001b[0m in \u001b[0;36mpreprocessing\u001b[0;34m(self, input_next_state, isStart)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m#transform = T.Grayscale()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGrayscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToPILImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torchvision.transforms' has no attribute 'numpy'"
          ]
        }
      ]
    }
  ]
}